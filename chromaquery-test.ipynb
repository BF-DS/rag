{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cff8b5",
   "metadata": {},
   "source": [
    "# How to access a persistent ChromaDB vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9eba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486af990",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Load environment variables from .env file\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Set OpenAI API key from environment variable\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "persist_dir = \"./vector_store\"  # Directory to save the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # Use a smaller model for faster processing\n",
    "    openai_api_key=openai.api_key,  # Set OpenAI API key for embeddings\n",
    ")\n",
    "\n",
    "vector_db = Chroma(\n",
    "    collection_name=\"book-rag\",  # Name of the collection in the vector store\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_dir,  # Directory to save the vector store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cae180",
   "metadata": {},
   "source": [
    "## Summary and Additional Tips\n",
    "\n",
    "### Key Querying Methods:\n",
    "\n",
    "1. **LangChain Methods:**\n",
    "   - `similarity_search(query, k=n)` - Basic similarity search\n",
    "   - `similarity_search_with_score(query, k=n)` - With relevance scores\n",
    "   - `similarity_search(query, k=n, filter={})` - With metadata filters\n",
    "\n",
    "2. **Direct ChromaDB Methods:**\n",
    "   - `collection.query(query_texts=[], n_results=n)` - Basic query\n",
    "   - `collection.query(query_embeddings=[], n_results=n)` - With embeddings\n",
    "   - `collection.query(where={}, n_results=n)` - With metadata filters\n",
    "\n",
    "3. **Useful Parameters:**\n",
    "   - `k` or `n_results`: Number of documents to return\n",
    "   - `include`: What to include in results ['metadatas', 'documents', 'distances']\n",
    "   - `where`: Metadata filtering conditions\n",
    "   - `filter`: LangChain metadata filtering\n",
    "\n",
    "4. **Performance Tips:**\n",
    "   - Use smaller `k` values for faster queries\n",
    "   - Use metadata filtering to narrow down search space\n",
    "   - Consider using direct embeddings for repeated similar queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b02b94",
   "metadata": {},
   "source": [
    "# Var1: Persistent Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a94f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['980d8491-849a-4916-afd0-f6481315151d',\n",
       "  'b7644c28-3f13-498a-9dcd-d0def691dd8f',\n",
       "  '66a97b10-e31a-4206-ae0b-6d4b3e437aaa',\n",
       "  'e7f848e6-dcbb-49a9-b34a-b61968a4e5ee',\n",
       "  '0d18b382-9bc6-43b9-bc5b-bbb516b4fea3',\n",
       "  'a8a2302d-b610-4000-9f25-9ef35b3a6363',\n",
       "  '6e29481f-6352-4e9b-af92-ca09242382e3',\n",
       "  '948f2917-95d2-47b7-a4b5-6d7271659d3a',\n",
       "  'b3018478-be24-4f4d-b733-eb819b07f654',\n",
       "  '21d360ac-9a8a-4648-801f-4ffc07f94f3b'],\n",
       " 'embeddings': array([[-0.04114935,  0.01725916, -0.0259696 , ..., -0.0274252 ,\n",
       "          0.01073788, -0.01724761],\n",
       "        [-0.02594493,  0.05223745,  0.02822908, ..., -0.02153802,\n",
       "          0.00872693,  0.00682761],\n",
       "        [-0.04504454,  0.01727702,  0.02702175, ..., -0.02781724,\n",
       "         -0.01397077,  0.01471654],\n",
       "        ...,\n",
       "        [-0.02168313,  0.01067083,  0.02736986, ..., -0.01000103,\n",
       "         -0.0144598 ,  0.01296917],\n",
       "        [ 0.03294064,  0.03395545,  0.02321879, ...,  0.0131722 ,\n",
       "          0.00389179,  0.01176162],\n",
       "        [-0.03101617,  0.03568044,  0.04212043, ..., -0.02729897,\n",
       "          0.01475044,  0.00013854]], shape=(10, 1536)),\n",
       " 'documents': ['»Eine erfrischende \\nund inspirierende \\nRessource. Vollge\\xad\\npackt mit praktischen \\nAnleitungen und \\nklaren Erläuterungen, \\ndie Ihren Horizont auf \\ndiesem spektakulären \\nneuen Gebiet \\nerweitern.«\\n— Pete Huang\\nAutor von The Neuron\\nPraxiseinstieg Large Language Models\\nSinan Ozdemir ist KI-Unternehmer \\nund Venture-Capital-Berater \\nund hat einen Master in Mathe-\\nmatik. Als Gründer und CTO \\nvon LoopGenius lotet er mit \\nseinem Team die Möglichkeiten \\nmodernster KI-Anwendungen für \\nUnternehmensgründungen und das \\nManagement aus. \\nAn der Johns Hopkins University \\nin Baltimore hat er Vorlesungen \\nin Data Science gehalten und \\nmehrere Lehrbücher zu Data \\nScience und Machine Learning \\nverfasst. Außerdem war er Gründer \\nder KI-Plattform Kylie.ai, die die \\nMöglichkeiten der Conversational \\nAI mit Robotic Process Automation \\n(RPA) zusammengeführt hat.\\nEuro  39,90 (D)  \\nISBN 978-3-96009-240-7\\nInteresse am E-Book? \\nwww.dpunkt.pluswww.dpunkt.de\\nGedruckt in Deutschland',\n",
       "  'Gedruckt in Deutschland\\nPapier aus nachhaltiger Waldwirtschaft\\nMineralölfreie Druckfarben\\nDeutsche\\n \\nAusgabe\\nStrategien und Best Practices für den  \\nEinsatz von ChatGPT und anderen LLMs\\nPraxiseinstieg\\nModels\\nSinan Ozdemir\\nÜbersetzung von Frank Langenau\\nOzdemir Praxiseinstieg Large Language Models\\nLarge Language Models (LLMs) wie ChatGPT sind enorm \\nleistungsfähig, aber auch sehr komplex. Praktikerinnen und \\nPraktiker stehen daher vor vielfältigen Herausforderungen, \\nwenn sie LLMs in ihre eigenen Anwendungen integrieren wollen. \\nIn dieser Einführung räumt Data Scientist und KI-Unternehmer \\nSinan Ozdemir diese Hürden aus dem Weg und bietet einen \\nLeitfaden für den Einsatz von LLMs zur Lösung praktischer \\nProbleme des Natural Language Processings.\\nSinan Ozdemir hat alles zusammengestellt, was Sie für den \\nEinstieg benötigen: Schritt-für-Schritt-Anleitungen, Best Practices, \\nFallstudien aus der Praxis, Übungen und vieles mehr. Er stellt',\n",
       "  'die Funktionsweise von LLMs vor und unterstützt Sie so dabei, \\ndas für Ihre Anwendung passende Modell und geeignete \\nDatenformate und Parameter auszuwählen. Dabei zeigt er das \\nPotenzial sowohl von Closed-Source- als auch von Open-Source-\\nLLMs wie GPT-3, GPT-4 und ChatGPT, BERT und T5, GPT- J und \\nGPT-Neo, Cohere sowie BART.\\n• Lernen Sie die Schlüsselkonzepte kennen: Transfer Learning, \\nFeintuning, Attention, Embeddings, Tokenisierung und mehr\\n• Nutzen Sie APIs und Python, um LLMs an Ihre Anforde run\\xad\\ngen anzupassen\\n• Beherrschen Sie Prompt\\xadEngineering\\xadTechniken wie \\nAusgabe\\xadStrukturierung, Gedankenketten und Few\\xadShot\\xad\\nPrompting\\n• Passen Sie LLM-Embeddings an, um eine Empfehlungs\\xad\\nengine mit eigenen Benutzerdaten neu zu erstellen\\n• Konstruieren Sie multimodale Transformer\\xadArchitekturen \\nmithilfe von Open\\xadSource\\xadLLMs\\n• Optimieren Sie LLMs mit Reinforcement Learning from \\nHuman and AI Feedback (RLHF/RLAIF)\\n• Deployen Sie Prompts und benutzerdefinierte, feingetunte \\nLLMs in die Cloud',\n",
       "  'LLMs in die Cloud\\nLarge Language',\n",
       "  'Lob für\\n»Praxiseinstieg Large Language Models«\\n»Indem er das Potenzial sowohl von Op en-Source- als auch von Closed-Source-\\nModellen abwägt, präsentiert sich Praxiseinstieg Large Language Models als umfas-\\nsender Leitfaden für das Verständnis und die Verwendung von LLMs, der die Kluft\\nzwischen theoretischen Konzepten und praktischer Anwendung überbrückt.«\\n– Giada Pistilli, Principal Ethicist bei Hugging Face\\n»Eine erfrischende und inspirierende Re ssource. Vollgepackt mit praktischen An-\\nleitungen und klaren Erläuterungen, die Si e in diesem spektakulären Gebiet klüger\\nmachen.«\\n– Pete Huang, Autor von The Neuron\\n»Wenn es darum geht, große Sprachmodelle ( Large Language Models , LLMs) zu\\nerstellen, erweist es sich mitunter als schwierig, umfassende Ressourcen zu finden,\\ndie alle wesentlichen Aspekte abdecken. Meine Suche nach einer solchen Res-\\nsource hatte jedoch kürzlich ein Ende, als ich dieses Buch entdeckte.',\n",
       "  'Sinan zeichnet sich unter anderem durch seine Fähigkeit aus, komplexe Konzepte\\nauf einfache Weise zu präsentieren. Der Autor hat hervorragende Arbeit geleistet,\\nindem er komplizierte Ideen und Algorithme n aufgeschlüsselt hat, sodass Leser sie\\nverstehen können, ohne sich überfordert zu fühlen. Er erklärt jedes Thema sorg-\\nfältig und baut dabei auf Be ispielen auf, die als Sprungbrett für ein besseres Ver-\\nständnis dienen. Dieser Ansatz bereichert  die Lernerfahrung und macht selbst die\\nkompliziertesten Aspekte der LLM-Entwicklung für Leserinnen und Leser mit un-\\nterschiedlichem Wissensstand zugänglich.\\nEine weitere Stärke dieses Buchs ist die Fülle an Coderessourcen. Das Einbeziehen\\nvon praktischen Beispielen und Codefragmenten ist ein Gamechanger für jeden,\\nder experimentieren und die gelernten Ko nzepte anwenden will. Diese Coderes-\\nsourcen vermitteln dem Leser praktische Erfahrungen und ermöglichen ihm, die ei-',\n",
       "  'genen Kenntnisse zu testen und aufzube ssern. Dies ist von unschätzbarem Wert,\\nda es ein tieferes Verständnis der Materie fördert und es dem Leser erlaubt, sich\\nwirklich mit dem Inhalt auseinanderzusetzen.\\nZusammenfassend lässt sich sagen, dass dieses Buch ein Glückstreffer für jeden ist,\\nder sich für den Aufbau von LLMs interessiert. Die außergewöhnliche Qualität der\\nErklärungen, der klare und prägnante Schr eibstil, die reichhaltigen Coderessour-\\ncen und die umfassende Abdeckung aller wesentlichen Aspekte machen es zu ei-\\nner unverzichtbaren Ressource. Ob Sie nun Anfänger oder erfahrener Praktiker\\nsind, dieses Buch wird zweifellos Ihr Ve rständnis und Ihre praktischen Fertigkei-\\nten in der LLM-Entwicklung erweitern. Ich empfehle Praxiseinstieg Large Lan-\\nguage Models jedem, der sich auf die aufregende Reise begeben will, LLM-Anwen-\\ndungen zu erstellen.«\\n– Pedro Marcelino, Machine Learning Engineer,\\nMitbegründer und CEO @overfit.study',\n",
       "  'Praxiseinstieg\\nLarge Language Models',\n",
       "  'Coypright und Urheberrechte:\\nDie durch die dpunkt.verlag GmbH vertriebenen digitalen Inhalte sind urheberrechtlich geschützt. Der Nutzer verpflichtet \\nsich, die Urheberrechte anzuerkennen und einzuhalten. Es werden keine Urheber-, Nutzungs- und sonstigen Schutzrechte \\nan den Inhalten auf den Nutzer übertragen. Der Nutzer ist nur berechtigt, den abgerufenen Inhalt zu eigenen Zwecken zu \\nnutzen. Er ist nicht berechtigt, den Inhalt im Internet, in Intranets, in Extranets oder sonst wie Dritten zur Verwertung zur \\nVerfügung zu stellen. Eine öffentliche Wiedergabe oder sonstige Weiterveröffentlichung und eine gewerbliche Vervielfäl-\\ntigung der Inhalte wird ausdrücklich ausgeschlossen. Der Nutzer darf Urheberrechtsvermerke, Markenzeichen und andere \\nRechtsvorbehalte im abgerufenen Inhalt nicht entfernen.',\n",
       "  'Praxiseinstieg\\nLarge Language Models\\nStrategien und Best Practices für den Einsatz\\nvon ChatGPT und anderen LLMs\\nSinan Ozdemir\\nDeutsche Übersetzung von\\nFrank Langenau'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'author': 'Sinan Ozdemir',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'keywords': '',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'copyright': 'O’Reilly',\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'page': 0,\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'page_label': '1',\n",
       "   'total_pages': 274},\n",
       "  {'copyright': 'O’Reilly',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'total_pages': 274,\n",
       "   'page_label': '1',\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'page': 0,\n",
       "   'keywords': '',\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'author': 'Sinan Ozdemir'},\n",
       "  {'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'page_label': '1',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'total_pages': 274,\n",
       "   'page': 0,\n",
       "   'keywords': '',\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'author': 'Sinan Ozdemir',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00'},\n",
       "  {'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'keywords': '',\n",
       "   'page': 0,\n",
       "   'total_pages': 274,\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'author': 'Sinan Ozdemir',\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'page_label': '1',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)'},\n",
       "  {'author': 'Sinan Ozdemir',\n",
       "   'page': 1,\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'page_label': '2',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'keywords': '',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'total_pages': 274,\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00'},\n",
       "  {'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'page': 1,\n",
       "   'author': 'Sinan Ozdemir',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'total_pages': 274,\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'page_label': '2',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'keywords': '',\n",
       "   'creator': 'FrameMaker 12.0.4'},\n",
       "  {'copyright': 'O’Reilly',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'page_label': '2',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'keywords': '',\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'page': 1,\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'total_pages': 274,\n",
       "   'author': 'Sinan Ozdemir'},\n",
       "  {'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'total_pages': 274,\n",
       "   'keywords': '',\n",
       "   'page': 2,\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'page_label': '3',\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'author': 'Sinan Ozdemir',\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\"},\n",
       "  {'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'keywords': '',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'page': 3,\n",
       "   'page_label': '4',\n",
       "   'total_pages': 274,\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'author': 'Sinan Ozdemir',\n",
       "   'creator': 'FrameMaker 12.0.4'},\n",
       "  {'title': 'Praxiseinstieg Larg Language Models',\n",
       "   'page_label': '5',\n",
       "   'total_pages': 274,\n",
       "   'creationdate': '2024-04-15T11:07:40+02:00',\n",
       "   'moddate': '2024-11-22T17:23:37+01:00',\n",
       "   'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\",\n",
       "   'creator': 'FrameMaker 12.0.4',\n",
       "   'keywords': '',\n",
       "   'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs',\n",
       "   'page': 4,\n",
       "   'producer': 'Acrobat Distiller 11.0 (Windows)',\n",
       "   'copyright': 'O’Reilly',\n",
       "   'author': 'Sinan Ozdemir'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=persist_dir)\n",
    "collection = persistent_client.get_or_create_collection(name=\"book-rag\")\n",
    "collection.peek()  # Check the contents of the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec76fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Information:\n",
      "Collection name: book-rag\n",
      "Collection count: 673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Collection statistics and information\n",
    "print(\"Collection Information:\")\n",
    "print(f\"Collection name: {collection.name}\")\n",
    "print(f\"Collection count: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc1e73",
   "metadata": {},
   "source": [
    "# Querying the Persistent ChromaDB Vector Store\n",
    "\n",
    "Now let's explore different ways to query the persistent ChromaDB vector store. We'll cover:\n",
    "1. Basic similarity search using LangChain\n",
    "2. Direct ChromaDB client queries\n",
    "3. Similarity search with metadata filtering\n",
    "4. Retrieving documents with scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390ce78",
   "metadata": {},
   "source": [
    "## Method 1: Basic Similarity Search using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5ac4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents for query: 'What are large language models?'\n",
      "\n",
      "Document 1:\n",
      "Content: Was sind Large Language Models? | 33\n",
      "Wie LLMs funktionieren\n",
      "Die Art und Weise, wie ein LLM vortrainiert und feingetunt wird, macht den Unter-\n",
      "schied zwischen einem Modell mit akzeptabler Leistung und ...\n",
      "Metadata: {'page_label': '33', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'creationdate': '2024-04-15T11:07:40+02:00', 'title': 'Praxiseinstieg Larg Language Models', 'total_pages': 274, 'copyright': 'O’Reilly', 'page': 32, 'producer': 'Acrobat Distiller 11.0 (Windows)', 'author': 'Sinan Ozdemir', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'moddate': '2024-11-22T17:23:37+01:00', 'keywords': '', 'creator': 'FrameMaker 12.0.4'}\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Content: Was sind Large Language Models? | 29\n",
      "Autoregressive Sprachmodelle werden so traini ert, dass sie das nächste Token in\n",
      "einem Satz vorhersagen, und zwar nur au f der Grundlage der vorherigen Token in\n",
      "de...\n",
      "Metadata: {'page_label': '29', 'moddate': '2024-11-22T17:23:37+01:00', 'copyright': 'O’Reilly', 'page': 28, 'keywords': '', 'total_pages': 274, 'title': 'Praxiseinstieg Larg Language Models', 'creationdate': '2024-04-15T11:07:40+02:00', 'creator': 'FrameMaker 12.0.4', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'author': 'Sinan Ozdemir', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\"}\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Content: | 23\n",
      "TEIL I\n",
      "Einführung in Large Language Models...\n",
      "Metadata: {'producer': 'Acrobat Distiller 11.0 (Windows)', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'copyright': 'O’Reilly', 'moddate': '2024-11-22T17:23:37+01:00', 'creator': 'FrameMaker 12.0.4', 'creationdate': '2024-04-15T11:07:40+02:00', 'page': 22, 'page_label': '23', 'title': 'Praxiseinstieg Larg Language Models', 'keywords': '', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'author': 'Sinan Ozdemir', 'total_pages': 274}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Basic similarity search using LangChain\n",
    "query = \"What are large language models?\"\n",
    "docs = vector_db.similarity_search(query, k=3)  # Get top 3 most similar documents\n",
    "\n",
    "print(f\"Found {len(docs)} documents for query: '{query}'\\n\")\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f40ec",
   "metadata": {},
   "source": [
    "## Method 2: Similarity Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f667310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents with scores for query: 'What are large language models?'\n",
      "\n",
      "Document 1 (Score: 0.6233):\n",
      "Content: Was sind Large Language Models? | 33\n",
      "Wie LLMs funktionieren\n",
      "Die Art und Weise, wie ein LLM vortrainiert und feingetunt wird, macht den Unter-\n",
      "schied zwischen einem Modell mit akzeptabler Leistung und ...\n",
      "Metadata: {'page': 32, 'producer': 'Acrobat Distiller 11.0 (Windows)', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'page_label': '33', 'title': 'Praxiseinstieg Larg Language Models', 'creator': 'FrameMaker 12.0.4', 'keywords': '', 'total_pages': 274, 'author': 'Sinan Ozdemir', 'copyright': 'O’Reilly', 'moddate': '2024-11-22T17:23:37+01:00', 'creationdate': '2024-04-15T11:07:40+02:00', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\"}\n",
      "--------------------------------------------------\n",
      "Document 2 (Score: 0.6407):\n",
      "Content: Was sind Large Language Models? | 29\n",
      "Autoregressive Sprachmodelle werden so traini ert, dass sie das nächste Token in\n",
      "einem Satz vorhersagen, und zwar nur au f der Grundlage der vorherigen Token in\n",
      "de...\n",
      "Metadata: {'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'creator': 'FrameMaker 12.0.4', 'total_pages': 274, 'title': 'Praxiseinstieg Larg Language Models', 'copyright': 'O’Reilly', 'page': 28, 'keywords': '', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'moddate': '2024-11-22T17:23:37+01:00', 'page_label': '29', 'creationdate': '2024-04-15T11:07:40+02:00', 'author': 'Sinan Ozdemir', 'producer': 'Acrobat Distiller 11.0 (Windows)'}\n",
      "--------------------------------------------------\n",
      "Document 3 (Score: 0.6444):\n",
      "Content: | 23\n",
      "TEIL I\n",
      "Einführung in Large Language Models...\n",
      "Metadata: {'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'title': 'Praxiseinstieg Larg Language Models', 'page': 22, 'total_pages': 274, 'moddate': '2024-11-22T17:23:37+01:00', 'copyright': 'O’Reilly', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'author': 'Sinan Ozdemir', 'keywords': '', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'page_label': '23', 'creationdate': '2024-04-15T11:07:40+02:00', 'creator': 'FrameMaker 12.0.4'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Similarity search with relevance scores\n",
    "docs_with_scores = vector_db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(f\"Found {len(docs_with_scores)} documents with scores for query: '{query}'\\n\")\n",
    "for i, (doc, score) in enumerate(docs_with_scores, 1):\n",
    "    print(f\"Document {i} (Score: {score:.4f}):\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7859e8b",
   "metadata": {},
   "source": [
    "## Method 3: Direct ChromaDB Client Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4279356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LangChain wrapper for consistent embeddings:\n",
      "Found 3 documents using LangChain wrapper:\n",
      "\n",
      "Document 1:\n",
      "Content: tung\n",
      "Fehlinterpretation von \n",
      "Anweisungen, Überanpas-\n",
      "sung an das Trainingsset, \n",
      "spärliches Belohnungssig-\n",
      "nal beim Reinforcement \n",
      "Learning\n",
      "Nutzung verschiedener \n",
      "Trainingsdatensets, um die \n",
      "Vielfalt d...\n",
      "Metadata: {'page_label': '264', 'total_pages': 274, 'title': 'Praxiseinstieg Larg Language Models', 'moddate': '2024-11-22T17:23:37+01:00', 'creationdate': '2024-04-15T11:07:40+02:00', 'creator': 'FrameMaker 12.0.4', 'keywords': '', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'copyright': 'O’Reilly', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'author': 'Sinan Ozdemir', 'page': 263}\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Content: SAWYER: Sinans Versuch, kluge und dennoch fesselnde Antworten zu geben | 221\n",
      "hersage trifft, sondern auch daran, wie sicher es in seinen Vorhersagen ist. Die nega-\n",
      "tive Log-Likelihood dient dazu, Mode...\n",
      "Metadata: {'title': 'Praxiseinstieg Larg Language Models', 'creator': 'FrameMaker 12.0.4', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'total_pages': 274, 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'author': 'Sinan Ozdemir', 'keywords': '', 'page': 220, 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'copyright': 'O’Reilly', 'creationdate': '2024-04-15T11:07:40+02:00', 'page_label': '221', 'moddate': '2024-11-22T17:23:37+01:00'}\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Content: DasPromptfragtnachmehreren\n",
      "OptioneninFormeiner\n",
      "nummeriertenListe.\n",
      "DieAntwortdesLLMwurdedarauf\n",
      "ausgerichtet,wasderBenutzerhabenwill....\n",
      "Metadata: {'page': 80, 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'total_pages': 274, 'producer': 'Acrobat Distiller 11.0 (Windows)', 'copyright': 'O’Reilly', 'moddate': '2024-11-22T17:23:37+01:00', 'keywords': '', 'creationdate': '2024-04-15T11:07:40+02:00', 'page_label': '81', 'author': 'Sinan Ozdemir', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'creator': 'FrameMaker 12.0.4', 'title': 'Praxiseinstieg Larg Language Models'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Using pre-computed embeddings with direct ChromaDB:\n",
      "Found 3 documents using direct ChromaDB with embeddings:\n",
      "\n",
      "Document 1 (Distance: 1.9297):\n",
      "Content: tung\n",
      "Fehlinterpretation von \n",
      "Anweisungen, Überanpas-\n",
      "sung an das Trainingsset, \n",
      "spärliches Belohnungssig-\n",
      "nal beim Reinforcement \n",
      "Learning\n",
      "Nutzung verschiedener \n",
      "Trainingsdatensets, um die \n",
      "Vielfalt d...\n",
      "Metadata: {'creationdate': '2024-04-15T11:07:40+02:00', 'author': 'Sinan Ozdemir', 'page_label': '264', 'total_pages': 274, 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'moddate': '2024-11-22T17:23:37+01:00', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'keywords': '', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'page': 263, 'creator': 'FrameMaker 12.0.4', 'copyright': 'O’Reilly', 'title': 'Praxiseinstieg Larg Language Models'}\n",
      "--------------------------------------------------\n",
      "Document 2 (Distance: 1.9435):\n",
      "Content: SAWYER: Sinans Versuch, kluge und dennoch fesselnde Antworten zu geben | 221\n",
      "hersage trifft, sondern auch daran, wie sicher es in seinen Vorhersagen ist. Die nega-\n",
      "tive Log-Likelihood dient dazu, Mode...\n",
      "Metadata: {'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'page': 220, 'creationdate': '2024-04-15T11:07:40+02:00', 'keywords': '', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'moddate': '2024-11-22T17:23:37+01:00', 'total_pages': 274, 'producer': 'Acrobat Distiller 11.0 (Windows)', 'creator': 'FrameMaker 12.0.4', 'page_label': '221', 'copyright': 'O’Reilly', 'title': 'Praxiseinstieg Larg Language Models', 'author': 'Sinan Ozdemir'}\n",
      "--------------------------------------------------\n",
      "Document 3 (Distance: 1.9471):\n",
      "Content: DasPromptfragtnachmehreren\n",
      "OptioneninFormeiner\n",
      "nummeriertenListe.\n",
      "DieAntwortdesLLMwurdedarauf\n",
      "ausgerichtet,wasderBenutzerhabenwill....\n",
      "Metadata: {'producer': 'Acrobat Distiller 11.0 (Windows)', 'page_label': '81', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'copyright': 'O’Reilly', 'title': 'Praxiseinstieg Larg Language Models', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'author': 'Sinan Ozdemir', 'keywords': '', 'creationdate': '2024-04-15T11:07:40+02:00', 'total_pages': 274, 'creator': 'FrameMaker 12.0.4', 'moddate': '2024-11-22T17:23:37+01:00', 'page': 80}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Direct ChromaDB client query\n",
    "# Note: When using direct ChromaDB client queries with query_texts, \n",
    "# ChromaDB will use its default embedding function if no embedding function is set.\n",
    "# To avoid dimension mismatches, we can use the LangChain wrapper instead:\n",
    "\n",
    "print(\"Using LangChain wrapper for consistent embeddings:\")\n",
    "docs = vector_db.similarity_search(query, k=3)\n",
    "print(f\"Found {len(docs)} documents using LangChain wrapper:\\n\")\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Alternative: Use pre-computed embeddings with direct ChromaDB\n",
    "print(\"\\nUsing pre-computed embeddings with direct ChromaDB:\")\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results['documents'][0])} documents using direct ChromaDB with embeddings:\\n\")\n",
    "for i in range(len(results['documents'][0])):\n",
    "    print(f\"Document {i+1} (Distance: {results['distances'][0][i]:.4f}):\")\n",
    "    print(f\"Content: {results['documents'][0][i][:200]}...\")\n",
    "    print(f\"Metadata: {results['metadatas'][0][i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5da01c",
   "metadata": {},
   "source": [
    "## Method 4: Metadata Filtering\n",
    "\n",
    "You can filter documents based on metadata when querying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac147909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available metadata keys: ['total_pages', 'creator', 'keywords', 'creationdate', 'author', 'title', 'page_label', 'subject', 'producer', 'moddate', 'copyright', 'page', 'source']\n",
      "Example metadata: {'total_pages': 274, 'creator': 'FrameMaker 12.0.4', 'keywords': '', 'creationdate': '2024-04-15T11:07:40+02:00', 'author': 'Sinan Ozdemir', 'title': 'Praxiseinstieg Larg Language Models', 'page_label': '109', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'moddate': '2024-11-22T17:23:37+01:00', 'copyright': 'O’Reilly', 'page': 108, 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\"}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Filter by source using LangChain\n",
    "# This assumes your documents have a 'source' metadata field\n",
    "\n",
    "# First, let's see what metadata keys are available\n",
    "sample_docs = vector_db.similarity_search(\"test\", k=1)\n",
    "if sample_docs:\n",
    "    print(\"Available metadata keys:\", list(sample_docs[0].metadata.keys()))\n",
    "    print(\"Example metadata:\", sample_docs[0].metadata)\n",
    "else:\n",
    "    print(\"No documents found in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c36ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents with metadata filter for query: 'What are large language models?'\n",
      "\n",
      "Document 1:\n",
      "Content: tung\n",
      "Fehlinterpretation von \n",
      "Anweisungen, Überanpas-\n",
      "sung an das Trainingsset, \n",
      "spärliches Belohnungssig-\n",
      "nal beim Reinforcement \n",
      "Learning\n",
      "Nutzung verschiedener \n",
      "Trainingsdatensets, um die \n",
      "Vielfalt d...\n",
      "Metadata: {'title': 'Praxiseinstieg Larg Language Models', 'copyright': 'O’Reilly', 'creationdate': '2024-04-15T11:07:40+02:00', 'keywords': '', 'author': 'Sinan Ozdemir', 'page_label': '264', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'creator': 'FrameMaker 12.0.4', 'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'page': 263, 'total_pages': 274, 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'moddate': '2024-11-22T17:23:37+01:00'}\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Content: SAWYER: Sinans Versuch, kluge und dennoch fesselnde Antworten zu geben | 221\n",
      "hersage trifft, sondern auch daran, wie sicher es in seinen Vorhersagen ist. Die nega-\n",
      "tive Log-Likelihood dient dazu, Mode...\n",
      "Metadata: {'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'title': 'Praxiseinstieg Larg Language Models', 'keywords': '', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'page': 220, 'page_label': '221', 'author': 'Sinan Ozdemir', 'creator': 'FrameMaker 12.0.4', 'copyright': 'O’Reilly', 'creationdate': '2024-04-15T11:07:40+02:00', 'total_pages': 274, 'moddate': '2024-11-22T17:23:37+01:00', 'producer': 'Acrobat Distiller 11.0 (Windows)'}\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Content: DasPromptfragtnachmehreren\n",
      "OptioneninFormeiner\n",
      "nummeriertenListe.\n",
      "DieAntwortdesLLMwurdedarauf\n",
      "ausgerichtet,wasderBenutzerhabenwill....\n",
      "Metadata: {'subject': 'Strategien und Best Practices für den Einsatz von ChatGPT und anderen LLMs', 'title': 'Praxiseinstieg Larg Language Models', 'source': \"documents/O'Reilly_Praxiseinstieg Large Language Models Einsatz von ChatGPT und anderen LLMs.pdf\", 'copyright': 'O’Reilly', 'keywords': '', 'producer': 'Acrobat Distiller 11.0 (Windows)', 'moddate': '2024-11-22T17:23:37+01:00', 'creator': 'FrameMaker 12.0.4', 'creationdate': '2024-04-15T11:07:40+02:00', 'page': 80, 'total_pages': 274, 'author': 'Sinan Ozdemir', 'page_label': '81'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Filter by specific metadata using LangChain\n",
    "# Uncomment and modify based on your metadata structure\n",
    "docs_filtered = vector_db.similarity_search(\n",
    "     query,\n",
    "     k=3,\n",
    "     filter={\"author\": \"Sinan Ozdemir\"}  # Filter by source\n",
    " )\n",
    "\n",
    "print(f\"Found {len(docs_filtered)} documents with metadata filter for query: '{query}'\\n\")\n",
    "for i, doc in enumerate(docs_filtered, 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Example 3: Using direct ChromaDB client with metadata filters\n",
    "# You can use where clause with ChromaDB for more complex filtering\n",
    "# filtered_results = collection.query(\n",
    "#     query_texts=[query],\n",
    "#     n_results=3,\n",
    "#     # where={\"source\": {\"$eq\": \"specific_document.pdf\"}},  # Uncomment to filter by source\n",
    "#     include=['metadatas', 'documents', 'distances']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38a02a",
   "metadata": {},
   "source": [
    "## Method 5: Vector Search with Custom Parameters\n",
    "\n",
    "Let's explore more advanced query parameters and options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "889514d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query using direct embeddings:\n",
      "Document 1 (Distance: 0.6233):\n",
      "Content: Was sind Large Language Models? | 33\n",
      "Wie LLMs funktionieren\n",
      "Die Art und Weise, wie ein LLM vortrainiert und feingetunt wird, macht den Unter-\n",
      "schied z...\n",
      "----------------------------------------\n",
      "Document 2 (Distance: 0.6407):\n",
      "Content: Was sind Large Language Models? | 29\n",
      "Autoregressive Sprachmodelle werden so traini ert, dass sie das nächste Token in\n",
      "einem Satz vorhersagen, und zwar...\n",
      "----------------------------------------\n",
      "Document 3 (Distance: 0.6444):\n",
      "Content: | 23\n",
      "TEIL I\n",
      "Einführung in Large Language Models...\n",
      "----------------------------------------\n",
      "Document 4 (Distance: 0.6526):\n",
      "Content: Was sind Large Language Models? | 31\n",
      "Wie schon erwähnt, lassen sich LLMs im Allgemeinen drei Hauptkategorien zuord-\n",
      "nen:\n",
      "• Autoregressive Modelle wie ...\n",
      "----------------------------------------\n",
      "Document 5 (Distance: 0.6567):\n",
      "Content: Was sind Large Language Models? | 39\n",
      "Abbildung 1-11: LLMs können alles Mögliche über die Welt lernen, seien es die Regeln und \n",
      "Strategien eines Spiels...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Query with embeddings directly\n",
    "# Get embeddings for your query\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Use ChromaDB to query with the embedding directly\n",
    "embedding_results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")\n",
    "\n",
    "print(\"Query using direct embeddings:\")\n",
    "for i in range(len(embedding_results['documents'][0])):\n",
    "    print(f\"Document {i+1} (Distance: {embedding_results['distances'][0][i]:.4f}):\")\n",
    "    print(f\"Content: {embedding_results['documents'][0][i][:150]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3a315",
   "metadata": {},
   "source": [
    "## Method 6: Multiple Query Types and Collection Operations\n",
    "\n",
    "Let's explore other useful operations with your persistent vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Information:\n",
      "Collection name: book-rag\n",
      "Collection count: 673\n",
      "\n",
      "Multiple queries:\n",
      "\n",
      "Query 1: What are transformers in NLP?\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Collection expecting embedding with dimension of 1536, got 384",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, query_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(multiple_queries, \u001b[32m1\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuery \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     results = \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistances\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results[\u001b[33m'\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])):\n\u001b[32m     23\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Result \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Distance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][j]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][j][:\u001b[32m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ben-s\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:221\u001b[39m, in \u001b[36mCollection.query\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[32m    186\u001b[39m \n\u001b[32m    187\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m \n\u001b[32m    207\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m query_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_query_request(\n\u001b[32m    210\u001b[39m     query_embeddings=query_embeddings,\n\u001b[32m    211\u001b[39m     query_texts=query_texts,\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m     include=include,\n\u001b[32m    219\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m query_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhere\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhere_document\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_query_response(\n\u001b[32m    234\u001b[39m     response=query_results, include=query_request[\u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    235\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ben-s\\anaconda3\\envs\\rag\\Lib\\site-packages\\chromadb\\api\\rust.py:505\u001b[39m, in \u001b[36mRustBindingsAPI._query\u001b[39m\u001b[34m(self, collection_id, query_embeddings, ids, n_results, where, where_document, include, tenant, database)\u001b[39m\n\u001b[32m    489\u001b[39m filtered_ids_amount = \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28mself\u001b[39m.product_telemetry_client.capture(\n\u001b[32m    491\u001b[39m     CollectionQueryEvent(\n\u001b[32m    492\u001b[39m         collection_uuid=\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    502\u001b[39m     )\n\u001b[32m    503\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m rust_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\n\u001b[32m    518\u001b[39m     ids=rust_response.ids,\n\u001b[32m    519\u001b[39m     embeddings=rust_response.embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    525\u001b[39m     distances=rust_response.distances,\n\u001b[32m    526\u001b[39m )\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Collection expecting embedding with dimension of 1536, got 384"
     ]
    }
   ],
   "source": [
    "# Example 2: Multiple queries at once\n",
    "multiple_queries = [\n",
    "    \"What are transformers in NLP?\",\n",
    "    \"How do language models work?\",\n",
    "    \"What is attention mechanism?\"\n",
    "]\n",
    "\n",
    "print(\"Multiple queries:\")\n",
    "for i, query_text in enumerate(multiple_queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query_text}\")\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=2,\n",
    "        include=['documents', 'distances']\n",
    "    )\n",
    "    for j in range(len(results['documents'][0])):\n",
    "        print(f\"  Result {j+1} (Distance: {results['distances'][0][j]:.4f}): {results['documents'][0][j][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
